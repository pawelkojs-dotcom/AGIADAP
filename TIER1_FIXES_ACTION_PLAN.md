# ACTION PLAN - FIXING HIDDEN ASSUMPTIONS
**Priorytet:** Tier 1 Critical for Falsifiability  
**Timeline:** Q1 2026  
**Cel:** Transform FIT ‚Üí PREDICTION

---

## üéØ TIER 1 FIXES (CRITICAL)

### FIX #1: Œò NORMALIZATION FROM FIRST PRINCIPLES

**Problem:** Obecnie Œò(z=10^13) = 1.0 jest arbitrary

**RozwiƒÖzanie A: BBN Constraint (RECOMMENDED - easiest)**

```python
# Algorytm:

1. Wstecz od BBN (z ~ 10^9):
   
   Constraint: |ŒîG/G|_BBN < 0.2
   
   gdzie: ŒîG/G = Œ±_M ~ dln(Œò)/dln(a)
   
2. Backward integrate:
   
   dŒò/dz = [chosen functional form]
   
   with boundary condition:
   |d ln Œò / d ln(1+z)|_{z_BBN} < 0.2
   
3. Normalizacja wynika automatycznie:
   
   Œò(z=10^13) = Œò(z_BBN) * exp[‚à´_{z_BBN}^{10^13} Œ≤(z') dz']
```

**Implementacja:**

```python
def find_theta_normalization_from_BBN():
    """
    Determine Œò normalization from BBN constraint
    """
    
    # BBN constraint
    z_BBN = 1e9
    max_dG_over_G = 0.2
    
    # Choose functional form for Œ≤(z) = d ln Œò / d ln(1+z)
    # Option 1: Constant
    # Option 2: Power law Œ≤(z) = Œ≤_0 * (1+z)^n
    # Option 3: From channel closures
    
    def beta_function(z, params):
        """RG Œ≤-function"""
        # Example: Œ≤ = Œ≤_0 for z > z_QCD, Œ≤ = 0 for z < z_thermal
        if z > 6e11:  # QCD era
            return params['beta_UV']
        elif z > 4e9:  # Weak era
            return params['beta_mid']
        else:  # Thermal era
            return params['beta_IR']
    
    # Backward integration
    def integrate_theta_backward(beta_params):
        z_grid = np.logspace(3, 13, 1000)[::-1]  # 10^13 ‚Üí 10^3
        
        ln_theta = np.zeros_like(z_grid)
        ln_theta[0] = 0  # Start at z=10^13, ln(Œò/Œò_ref) = 0
        
        for i in range(1, len(z_grid)):
            dz = z_grid[i-1] - z_grid[i]
            beta = beta_function(z_grid[i], beta_params)
            
            # d ln Œò / dz = Œ≤(z) / (1+z)
            d_ln_theta = beta / (1 + z_grid[i]) * dz
            ln_theta[i] = ln_theta[i-1] + d_ln_theta
        
        theta_grid = np.exp(ln_theta)
        return z_grid, theta_grid
    
    # Check BBN constraint
    def check_BBN_constraint(z_grid, theta_grid):
        # Find Œ±_M at z_BBN
        idx_BBN = np.argmin(np.abs(z_grid - z_BBN))
        
        # Œ±_M ~ d ln Œò / d ln a = -d ln Œò / d ln(1+z)
        alpha_M = -np.gradient(np.log(theta_grid), np.log(1+z_grid))[idx_BBN]
        
        return np.abs(alpha_M) < max_dG_over_G
    
    # Optimize to satisfy BBN
    # ...
    
    return optimal_theta_normalization
```

**Zalety:**
- Solidny physical constraint (BBN well-tested)
- Wymaga tylko RG flow Œ≤(z), nie pe≈Çnej metric perturbations
- Mo≈ºna zaimplementowaƒá w tydzie≈Ñ

**Wady:**
- Nadal trzeba za≈Ço≈ºyƒá functional form Œ≤(z)
- Po≈õrednie (przez Œ±_M), nie bezpo≈õrednie

---

**RozwiƒÖzanie B: Planck Scale (MOST FUNDAMENTAL)**

**Idea:**
```
Œò_Planck = M_Planck¬≤ c‚Å¥ / ‚Ñè ~ (10^19 GeV)¬≤ ~ 10^76 eV¬≤

Information temperature at Planck epoch:
Œò(t_Planck) ~ Œò_Planck

As universe cools:
Œò(z) = Œò_Planck * [scaling function]
```

**Implementacja wymaga:**
1. Connection OD ‚Üî quantum gravity
2. Œò as geometric quantity (curvature scale?)
3. Running from Planck ‚Üí QCD

**Timeline:** 6+ months (deep theory work)

---

**RozwiƒÖzanie C: CMB Acoustic Scale**

**Idea:**
```
Œ∏_* = r_s(z_*) / d_A(z_*)  # Angular size of sound horizon

If Œò modifies H(z):
‚Üí Modified r_s
‚Üí Modified Œ∏_*

Constraint from Planck: Œ∏_* = 0.596¬∞ ¬± 0.001¬∞
```

**Wymaga:**
- Full H_OD(z, Œò) implementation
- Self-consistent Boltzmann solver

**Timeline:** 2-3 months (after H_OD implemented)

---

**RECOMMENDATION:** Start with **Solution A (BBN)**, move to **Solution B (Planck)** long-term

---

### FIX #2: Œº-DISTORTIONS FROM MICROPHYSICS

**Problem:** Obecnie Œº scaled empirycznie ≈ºeby by≈Ç detekowalny

**RozwiƒÖzanie: Energy Budget from F = E - ŒòS**

**Krok 1: Oblicz S(z) - Configurational Entropy**

```python
def compute_configurational_entropy(z, Theta, Gamma_i):
    """
    S ‚âà -Œ£_i [Œì_i ln Œì_i + (1-Œì_i) ln(1-Œì_i)]
    
    Entropy from channel mixing
    """
    S = 0
    for Gamma in [Gamma_QCD, Gamma_weak, Gamma_thermal]:
        # Avoid log(0)
        if Gamma > 1e-10 and Gamma < 1-1e-10:
            S += -(Gamma * np.log(Gamma) + 
                   (1-Gamma) * np.log(1-Gamma))
    
    # Scale factor (from density of states, needs theory input)
    S *= S_0  # To be determined
    
    return S
```

**Krok 2: Energy Release**

```python
def energy_injection_rate(z, Theta, S):
    """
    From F = E - ŒòS:
    
    If F ‚âà const (equilibrium tracking):
    dE/dz = Œò dS/dz + S dŒò/dz
    """
    
    dS_dz = np.gradient(S, z)
    dTheta_dz = np.gradient(Theta, z)
    
    # Energy injection per comoving volume per z
    dE_dz = Theta * dS_dz + S * dTheta_dz
    
    return dE_dz
```

**Krok 3: Œº Calculation**

```python
def compute_mu_from_energy(z, dE_dz, T_CMB):
    """
    Œº = (1/4) * ‚à´ [dE/dt] / [œÅ_Œ≥ c¬≤] * W_Kompaneets(z) dt
    
    gdzie:
    - dE/dt energy injection rate per volume
    - œÅ_Œ≥ photon energy density
    - W_Kompaneets window function
    """
    
    # Convert dE/dz to dE/dt
    H_z = H(z)  # Hubble parameter
    dE_dt = dE_dz * H_z * (1+z)
    
    # Photon energy density
    rho_gamma = (œÄ¬≤/15) * (k_B * T_CMB * (1+z))**4 / (‚Ñè¬≥ c‚Åµ)
    
    # Kompaneets window (suppression at high z where Compton is strong)
    # Effective for z < 2√ó10^6 (T > 30 keV)
    z_mu_cutoff = 2e6
    W = np.exp(-(z/z_mu_cutoff)**2)
    
    # Integrate
    integrand = (dE_dt / (rho_gamma * c**2)) * W / H_z / (1+z)
    
    mu = (1/4) * np.trapz(integrand, z)
    
    return mu
```

**Expected result:**
- Œº mo≈ºe byƒá anywhere from 10^-10 to 10^-7
- **To jest OK** - to jest prediction, nie tuning!
- Je≈õli wyjdzie 10^-10: "below PIXIE, wait for next generation"
- Je≈õli wyjdzie 10^-7: "strong signal!"

**Key point:**
```
S_0 scale factor w compute_configurational_entropy
‚Üë
To jedyny remaining free parameter

Mo≈ºna ustaliƒá z:
- Entropy density Planck era (s ~ k_B (T/T_Planck)¬≥)
- Or: fit to ONE observable (e.g., CMB normalization)
```

**Timeline:** 2 tygodnie implementacji + testing

---

### FIX #3: SELF-CONSISTENT BACKGROUND H_OD(z, Œò)

**Problem:** Obecnie u≈ºywamy H_ŒõCDM(z), ale OD powinno modyfikowaƒá background

**RozwiƒÖzanie: Modified Friedmann Equations**

**Krok 1: OD Correction to Energy Density**

```python
# Standard:
H¬≤ = (8œÄG/3) * (œÅ_matter + œÅ_radiation + œÅ_Œõ)

# OD-modified:
H_OD¬≤ = (8œÄG/3) * (œÅ_matter + œÅ_radiation + œÅ_Œõ - Œò*S)
                                                  ‚Üë
                                    Free energy correction
```

**Implementacja:**

```python
def H_OD(z, Theta, S, params):
    """
    Modified Hubble parameter including OD correction
    """
    
    # Standard components
    H0 = params['H0']
    Omega_m = params['Omega_m']
    Omega_r = params['Omega_r']
    Omega_Lambda = params['Omega_Lambda']
    
    rho_m = Omega_m * (1+z)**3
    rho_r = Omega_r * (1+z)**4
    rho_Lambda = Omega_Lambda
    
    # OD correction (convert Œò*S to density units)
    rho_OD = -Theta * S / (some_scale_factor)
    
    # Total
    H = H0 * np.sqrt(rho_m + rho_r + rho_Lambda + rho_OD)
    
    return H
```

**Krok 2: Coupled Evolution**

```python
def solve_coupled_system(z_array):
    """
    Solve coupled system:
    - dŒò/dz from channel closures
    - dS/dz from Œì_i evolution  
    - H(z) from Friedmann with Œò, S
    """
    
    def derivatives(state, z):
        Theta, S, Gamma_QCD, Gamma_weak = state
        
        # Current H
        H = H_OD(z, Theta, S, params)
        
        # Channel evolution (may depend on H through temperature)
        T = T_CMB_0 * (1+z)
        dGamma_QCD_dz = closure_rate(T, Theta) / H
        # ... similar for other channels
        
        # Entropy
        dS_dz = compute_dS_dz(Gamma_QCD, Gamma_weak, ...)
        
        # Theta evolution
        # Option 1: From RG Œ≤-function
        # Option 2: From variational principle Œ¥F/Œ¥Œò = 0
        dTheta_dz = ...
        
        return [dTheta_dz, dS_dz, dGamma_QCD_dz, ...]
    
    # Integrate
    initial_state = [Theta_0, S_0, 0, 0]  # At z_max
    solution = odeint(derivatives, initial_state, z_array)
    
    return solution
```

**Krok 3: Consistency Checks**

```python
def check_consistency(solution):
    """
    Verify:
    1. Age of universe t_0 = 13.8 ¬± 0.1 Gyr
    2. BBN timing correct (T ~ MeV at z ~ 10^9)
    3. Recombination at z_* ~ 1100
    4. Current H_0 in reasonable range
    """
    
    # Age
    z, H_array = solution['z'], solution['H']
    t_0 = integrate.trapz(1/((1+z)*H_array), z)
    
    # Convert to Gyr
    t_0_Gyr = t_0 * (speed_of_light / Mpc_to_m) / (3600*24*365.25*1e9)
    
    assert 13.7 < t_0_Gyr < 13.9, f"Age = {t_0_Gyr} Gyr out of range!"
    
    # BBN
    idx_BBN = find_nearest(z, 1e9)
    T_BBN = T_CMB_0 * (1 + z[idx_BBN]) * k_B / eV_to_Joule
    assert 0.1e6 < T_BBN < 10e6, "BBN temperature wrong!"
    
    # etc.
    
    return True
```

**Uwaga krytyczna:**

Je≈õli H_OD r√≥≈ºni siƒô od H_ŒõCDM o wiƒôcej ni≈º ~1% w dowolnym momencie:
‚Üí **Dramatically changes all observables**
‚Üí Musi byƒá re-computed:
   - CMB acoustic peaks
   - BAO scale  
   - Supernova luminosity distances
   - Structure formation

To jest **biggest deal** - dlatego self-consistency jest Tier 1!

**Timeline:** 1 miesiƒÖc (pe≈Çny solver + wszystkie checks)

---

## üìã IMPLEMENTATION ROADMAP

### Week 1-2: Œº from Microphysics
```
[x] Implement S(z) calculation
[x] Energy injection dE/dz
[x] Proper Œº integration
[x] Test: compare with empirical scaling
[ ] ‚Üí Expected: Different values, that's OK!
```

### Week 3-4: Œò Normalization from BBN
```
[ ] Code backward integration from z_BBN
[ ] Test different Œ≤(z) functional forms
[ ] Find normalization that satisfies |ŒîG/G| < 0.2
[ ] Sensitivity analysis
```

### Week 5-8: Self-Consistent Background
```
[ ] Implement coupled ODE system
[ ] H_OD with Œò*S correction
[ ] Full consistency checks (age, BBN, recombination)
[ ] Compare: H_OD vs H_ŒõCDM
[ ] If big difference: re-compute ALL observables
```

### Week 9-10: Validation
```
[ ] Run comprehensive tests
[ ] Compare old (phenomenological) vs new (first-principles)
[ ] Document changes
[ ] Update Paper A
```

---

## ‚ö†Ô∏è POTENTIAL OUTCOMES & WHAT THEY MEAN

### Outcome A: Œº ~ 10^-9 (Below PIXIE)

**Interpretation:**
- OD energy injection is real but subtle
- Need next-generation experiments (Œº-SPEC, CORE)
- Not a failure - just lower amplitude than hoped

**Action:**
- Emphasize: "Conservative prediction"
- Mention: "Future experiments will probe this"

### Outcome B: Œº ~ 10^-7 (Strong Signal)

**Interpretation:**
- OD has dramatic effect
- Should already be seeing hints in COBE/FIRAS
- Might be tension - need to check archival data

**Action:**
- Look for existing constraints
- May need to adjust S_0 to satisfy current limits

### Outcome C: H_OD >> H_ŒõCDM (Big Modification)

**Interpretation:**
- OD fundamentally changes cosmology
- All standard ruler measurements affected
- Might actually **resolve H_0 tension**!

**Action:**
- Complete re-analysis of all cosmological data
- This would be **huge** if consistent

### Outcome D: H_OD ‚âà H_ŒõCDM (Weak Modification)

**Interpretation:**
- OD effects mostly in perturbations, not background
- This is OK - many modified gravity theories work this way
- Simplifies analysis

**Action:**
- Justify: "Screening in background, active in structure"

---

## üéì PHILOSOPHY: EMBRACING UNCERTAINTY

**Key mindset shift:**

‚ùå OLD: "Adjust parameters to get detectable signal"  
‚úÖ NEW: "Calculate from first principles, accept result"

**Why this is better:**

1. **Falsifiability:**
   - If Œº_predicted ‚â† Œº_observed: Theory has problem
   - If Œº_tuned = Œº_observed: No information

2. **Scientific integrity:**
   - Reviewers respect honest predictions
   - Even "negative" results (Œº < detection) are valuable

3. **Theory development:**
   - Discrepancies point to missing physics
   - Opportunities for refinement

**Example from history:**
- Weinberg predicted cosmological constant Œõ ~ (meV)‚Å¥
- Seemed crazy at the time (too small)
- Turned out roughly correct!
- **Prediction matters, not whether it's "convenient"**

---

## ‚úÖ DELIVERABLES

Po zako≈Ñczeniu Tier 1 fixes bƒôdziesz mia≈Ç:

### Code:
```
od_cosmology_v2/
‚îú‚îÄ‚îÄ theta_normalization.py       # BBN-constrained
‚îú‚îÄ‚îÄ mu_from_microphysics.py      # No free scaling
‚îú‚îÄ‚îÄ self_consistent_background.py # H_OD(z, Œò, S)
‚îú‚îÄ‚îÄ validation_suite.py          # All consistency checks
‚îî‚îÄ‚îÄ comparison_v1_vs_v2.py       # Before/After
```

### Documentation:
```
- THEORETICAL_JUSTIFICATION.md   # Why each choice
- VALIDATION_REPORT.md           # All tests passed
- PARAMETER_TABLE.md             # Every assumption listed
```

### Paper Updates:
```
- New section: "First-Principles Derivation"
- Updated predictions (may differ from v1!)
- Honest uncertainty quantification
```

---

## üí™ CONCLUSION

**Obecny stan:**
- Framework: Strong ‚úÖ
- Implementation: Phenomenological ‚ö†Ô∏è

**Po Tier 1 fixes:**
- Framework: Strong ‚úÖ  
- Implementation: First-principles ‚úÖ

**Timeline:** ~8 weeks intensive work

**Risk:** Predictions may change (possibly weaken)  
**Benefit:** True falsifiability + scientific integrity

**Zalecenie:**
Do it. Science wins when we're honest, not when we're convenient.

**Starting point:**
Begin with FIX #2 (Œº from microphysics) - easiest, most impactful.
